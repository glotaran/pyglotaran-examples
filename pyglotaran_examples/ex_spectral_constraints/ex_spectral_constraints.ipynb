{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from glotaran.io import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"data/data.ascii\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "### Analysis without equal area penalties\n",
    "\n",
    "Example of a two step optimization\n",
    "- First do a (partial) optimization with first scheme\n",
    "- Extract the optimized schemed and adjust its settings\n",
    "- Optimize again with the second scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from glotaran.io import load_model, load_parameters\n",
    "from glotaran.optimization.optimize import optimize\n",
    "from glotaran.project.scheme import Scheme\n",
    "\n",
    "model = load_model(\"models/model.yml\")\n",
    "parameters = load_parameters(\"models/parameters.yml\")\n",
    "\n",
    "scheme_no_penalties = Scheme(\n",
    "    model=model,\n",
    "    parameters=parameters,\n",
    "    data={\"dataset1\": dataset},\n",
    "    optimization_method=\"TrustRegionReflection\",\n",
    "    maximum_number_function_evaluations=5,\n",
    ")\n",
    "\n",
    "# optimization with first scheme\n",
    "result = optimize(scheme_no_penalties)\n",
    "# optimization with second scheme,\n",
    "# where we change the maximum number of function evaluations\n",
    "scheme2 = result.get_scheme()\n",
    "scheme2.maximum_number_function_evaluations = 2\n",
    "result_no_penalties = optimize(scheme2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "#### Saving results and creating plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyglotaran_extras.io import setup_case_study\n",
    "\n",
    "from glotaran.io import save_result\n",
    "\n",
    "base_results_folder, _ = setup_case_study(output_folder_name=\"pyglotaran_examples_results\")\n",
    "results_folder = base_results_folder / \"no_penalties\"\n",
    "save_result(result_no_penalties, results_folder / \"result.yml\", allow_overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyglotaran_extras.plotting.plot_overview import plot_simple_overview\n",
    "\n",
    "plot_simple_overview(result_no_penalties.data[\"dataset1\"]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "### Analysis using equal area penalties\n",
    "\n",
    "This time we use equal parameter in our model, allowing us to estimate the relative amplitude between the two species."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glotaran.io import load_model, load_parameters\n",
    "from glotaran.optimization.optimize import optimize\n",
    "from glotaran.project.scheme import Scheme\n",
    "\n",
    "parameters = load_parameters(\"models/parameters_equal_area_penalties.yml\")\n",
    "model = load_model(\"models/model_equal_area_penalties.yml\")\n",
    "\n",
    "scheme_equal_area = Scheme(\n",
    "    model=model,\n",
    "    parameters=parameters,\n",
    "    data={\"dataset1\": dataset},\n",
    "    optimization_method=\"TrustRegionReflection\",\n",
    "    maximum_number_function_evaluations=7,\n",
    ")\n",
    "\n",
    "result_equal_area = optimize(scheme_equal_area)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "#### Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyglotaran_extras.plotting.plot_overview import plot_simple_overview\n",
    "\n",
    "plot_simple_overview(result_equal_area.data[\"dataset1\"]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyglotaran_extras.io import setup_case_study\n",
    "\n",
    "from glotaran.io import save_result\n",
    "\n",
    "base_results_folder, _ = setup_case_study(output_folder_name=\"pyglotaran_examples_results\")\n",
    "results_folder = base_results_folder / \"with_penalties_first_run\"\n",
    "save_result(result_equal_area, results_folder / \"result.yml\", allow_overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from glotaran.io import save_dataset\n",
    "\n",
    "for data_path in results_folder.rglob(\"*.nc\"):\n",
    "    save_dataset(load_dataset(data_path), results_folder / data_path.name, allow_overwrite=True)\n",
    "    data_path.unlink()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pygta-staging",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
